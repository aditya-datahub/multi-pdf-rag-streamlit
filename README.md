# ğŸ“š Multi-PDF RAG Streamlit App

A **Streamlit-based multi-PDF document Question & Answer system** using  
**Retrieval-Augmented Generation (RAG)** powered by **Llama-3 via Groq** and **ChromaDB**.

---

## ğŸš€ Features

- ğŸ“„ Upload **multiple PDFs**
- ğŸ” Semantic search using **HuggingFace embeddings**
- ğŸ§  Accurate answers using **Llama-3.3-70B (Groq)**
- ğŸ§© Vector storage with **ChromaDB**
- â“ Ask **multiple questions at once**
- ğŸ§  Clean **Question â†’ Answer** UI
- âš¡ Fast inference via **Groq API**

---

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ app.py # Streamlit app
â”œâ”€â”€ rag_utility.py # PDF processing + RAG logic
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ env_template.txt # Environment variable template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ§  How It Works (RAG Pipeline)

1. Upload PDFs using Streamlit
2. PDFs are:
   - Loaded using `UnstructuredPDFLoader`
   - Split into chunks
   - Converted into embeddings
3. Embeddings are stored in **ChromaDB**
4. User questions are:
   - Retrieved via similarity search
   - Passed to **Llama-3** with context
5. Model returns **grounded answers**

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/multi-pdf-rag-streamlit.git
cd multi-pdf-rag-streamlit
```
### 2ï¸âƒ£ Create a virtual environment (recommended)
```
conda create -n rag python=3.10
conda activate rag
```
### 3ï¸âƒ£ Install dependencies
```
pip install -r requirements.txt
(or copy env_template.txt â†’ .env)
```
---

## ğŸ” Environment Variables
Create a .env file in the root directory:
```
GROQ_API_KEY=your_groq_api_key_here
```
You can refer to env_template.txt for guidance.

---

## â–¶ï¸ Run the Application
```
streamlit run app.py
```
---

## ğŸ§ª Example Usage

1. Upload one or more PDFs
2. Enter questions (one per line), for example:
```
What is an ecosystem?
What are the types of ecosystems?
Forerunners of Evo-Devo?
```
3. Click Answer
4. Get structured Question â†’ Answer results

---

## ğŸ§© Tech Stack

1. Frontend: Streamlit
2. LLM: Llama-3.3-70B (Groq)
3. Embeddings: all-MiniLM-L6-v2
4. Vector Database: ChromaDB
5. Framework: LangChain
5. Language: Python

---

## ğŸŒ Deployment

This application is ready to deploy on:
1. Streamlit Cloud
2. Docker
3. Any cloud VM (AWS / GCP / Azure)

---

## ğŸ“œ License

This project is licensed under the MIT License.
You are free to use, modify, and distribute it.

---

## ğŸ™Œ Acknowledgements

1. Groq
2. LangChain
3. HuggingFace
4. Streamlit

---
