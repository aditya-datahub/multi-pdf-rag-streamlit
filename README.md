# ğŸ“š Multi-PDF RAG Streamlit App

A **Streamlit-based multi-PDF document Question & Answer system** using  
**Retrieval-Augmented Generation (RAG)** powered by **Llama-3 via Groq** and **ChromaDB**.

---

## ğŸš€ Features

- ğŸ“„ Upload **multiple PDFs**
- ğŸ” Semantic search using **HuggingFace embeddings**
- ğŸ§  Accurate answers using **Llama-3.3-70B (Groq)**
- ğŸ§© Vector storage with **ChromaDB**
- â“ Ask **multiple questions at once**
- ğŸ§  Clean **Question â†’ Answer** UI
- âš¡ Fast inference via **Groq API**

---

## ğŸ—ï¸ Project Structure

'''
â”œâ”€â”€ app.py # Streamlit app
â”œâ”€â”€ rag_utility.py # PDF processing + RAG logic
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ env_template.txt # Environment variable template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
'''

---

## ğŸ§  How It Works (RAG Pipeline)

1. Upload PDFs using Streamlit
2. PDFs are:
   - Loaded using `UnstructuredPDFLoader`
   - Split into chunks
   - Converted into embeddings
3. Embeddings are stored in **ChromaDB**
4. User questions are:
   - Retrieved via similarity search
   - Passed to **Llama-3** with context
5. Model returns **grounded answers**

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/multi-pdf-rag-streamlit.git
cd multi-pdf-rag-streamlit
```
### 2ï¸âƒ£ Create a virtual environment (recommended)
conda create -n rag python=3.10
conda activate rag

### 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
(or copy env_template.txt â†’ .env)

## ğŸ” Environment Variables
Create a .env file in the root directory:
```
GROQ_API_KEY=your_groq_api_key_here
```
You can refer to env_template.txt for guidance.

## â–¶ï¸ Run the Application
'''
streamlit run app.py
'''

## ğŸ§ª Example Usage

1. Upload one or more PDFs
2. Enter questions (one per line), for example:
```
What is an ecosystem?
What are the types of ecosystems?
Forerunners of Evo-Devo?
```
3. Click Answer
4. Get structured Question â†’ Answer results

## ğŸ§© Tech Stack

Frontend: Streamlit
LLM: Llama-3.3-70B (Groq)
Embeddings: all-MiniLM-L6-v2
Vector Database: ChromaDB
Framework: LangChain
Language: Python

## ğŸŒ Deployment

This application is ready to deploy on:
Streamlit Cloud
Docker
Any cloud VM (AWS / GCP / Azure)

## ğŸ“œ License

This project is licensed under the MIT License.
You are free to use, modify, and distribute it.

## ğŸ™Œ Acknowledgements

Groq
LangChain
HuggingFace
Streamlit
